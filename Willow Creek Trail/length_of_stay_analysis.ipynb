{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5391b63b",
   "metadata": {},
   "source": [
    "## CV Parking Lot Analysis\n",
    "\n",
    "#### Date: 9/30/2025\n",
    "#### Author: Nineveh O'Connell\n",
    "\n",
    "Goal: This notebook ingests csv output of computer vision model of the willow creek trailhead and output length of stay/turnover metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53aced58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41ca23",
   "metadata": {},
   "source": [
    "Define parking spot outlines (spot_id, minx, maxy, miny) and sort by minx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac058ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spot_boundaries = pd.DataFrame({\n",
    "    \"spot_id\": np.arange(1, 17),\n",
    "    \"minx\": [640, 549, 490, 430, 380, 330, 280, 240, 195, 165, 135, 112, 102, 75, 53, 28],\n",
    "    \"maxy\": [340, 340, 340, 340, 335, 325, 320, 320, 330, 320, 315, 310, 305, 300, 295, 295],\n",
    "    \"miny\": [265] * 16\n",
    "}).sort_values(\"minx\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f8fc9",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be52ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) read in data (adjust path as needed)\n",
    "csv_path = \"/Users/Nineveh.OConnell/OneDrive - DOT OST/volpe-portfolio-PublicLands - AI Real-Time Parking Project/Data/data_download_export_2025-09-30 20-23-29.csv\"\n",
    "in_willow_creek = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea33777",
   "metadata": {},
   "source": [
    "Assign to parking spots, calling the parking spot -1 in the case of being in the roadway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459a29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_willow_creek['parking_spot_id'] = pd.cut(in_willow_creek['cx'], bins = spot_boundaries['minx'], labels = np.arange(1,16)[::-1], right = True)\n",
    "\n",
    "# if midpoint has y higher (below) than 335, mark it as being in the roadway\n",
    "in_willow_creek['parking_spot_id'] = in_willow_creek['parking_spot_id'].cat.add_categories('-1')\n",
    "in_willow_creek.loc[in_willow_creek['cy'] > 335, 'parking_spot_id'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89821fe4",
   "metadata": {},
   "source": [
    "Make confidence into a numeric variable and only keep instances with confidence over 0.4. From spot checking, instances with lower confidence are not really vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67bf2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) extract numeric confidence from a string like \"label (0.82)\" into confidence_numeric\n",
    "#    regex captures the number inside parentheses (first occurrence)\n",
    "def extract_confidence(s):\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    m = re.search(r\"\\(([^)]+)\\)\", str(s))\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(1))\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "in_willow_creek[\"confidence_numeric\"] = in_willow_creek[\"confidence\"].apply(extract_confidence)\n",
    "\n",
    "# keep only rows where confidence is 0.35 or greater\n",
    "willow_creek_vehicles = in_willow_creek[in_willow_creek[\"confidence_numeric\"] > 0.35]\n",
    "# Clean up column\n",
    "willow_creek_vehicles = willow_creek_vehicles.drop(columns=[\"confidence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9de6bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nineveh.OConnell\\AppData\\Local\\Temp\\ipykernel_44668\\3817486738.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for (ts_val, spot_val), group in willow_creek_vehicles.groupby(group_cols, sort=False):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# parameters\n",
    "tolerance = 2                # pixels; consider duplicates when |dx| <= tolerance and |dy| <= tolerance\n",
    "\n",
    "# will collect kept rows\n",
    "kept_indices = []\n",
    "\n",
    "# group by timestamp and parking_spot_id\n",
    "group_cols = [\"timestamp\", \"parking_spot_id\"]\n",
    "\n",
    "# iterate groups — this is efficient unless you have extremely many tiny groups\n",
    "for (ts_val, spot_val), group in willow_creek_vehicles.groupby(group_cols, sort=False):\n",
    "    # convert group to numpy arrays for speed\n",
    "    # sort by confidence desc so first kept are the best\n",
    "    order = np.argsort(-group[\"confidence_numeric\"])\n",
    "    group_idx = group.index.to_numpy()[order]\n",
    "    cx_arr = group.loc[group_idx, \"cx\"].to_numpy()\n",
    "    cy_arr = group.loc[group_idx, \"cy\"].to_numpy()\n",
    "\n",
    "    # keep list of indices for this group\n",
    "    kept_for_group = []\n",
    "\n",
    "    # iterate detections in descending confidence order\n",
    "    for i, idx in enumerate(group_idx):\n",
    "        cx_i = cx_arr[i]\n",
    "        cy_i = cy_arr[i]\n",
    "\n",
    "        # if cx or cy is NaN, treat as not matching any kept point (so it can be kept only if best)\n",
    "        if np.isnan(cx_i) or np.isnan(cy_i):\n",
    "            # if the best entry is NaN and there are others non-NaN, this NaN will still be kept only\n",
    "            # if it has the highest confidence; follow the same logic as R code where exact matches matter\n",
    "            # Here, proceed to keep if no kept point exists (or if it's highest confidence)\n",
    "            if len(kept_for_group) == 0:\n",
    "                kept_for_group.append(idx)\n",
    "            continue\n",
    "\n",
    "        # check against already-kept points: if any kept point is within tolerance in both x and y, skip\n",
    "        if kept_for_group:\n",
    "            kept_cx = willow_creek_vehicles.loc[kept_for_group, \"cx\"].to_numpy()\n",
    "            kept_cy = willow_creek_vehicles.loc[kept_for_group, \"cy\"].to_numpy()\n",
    "\n",
    "            # compute boolean mask of kept points within tolerance (|dx| <= tol and |dy| <= tol)\n",
    "            # using broadcasting\n",
    "            dx = np.abs(kept_cx - cx_i)\n",
    "            dy = np.abs(kept_cy - cy_i)\n",
    "            within_tol = (dx <= tolerance) & (dy <= tolerance)\n",
    "\n",
    "            if np.any(within_tol):\n",
    "                # a kept point already within tolerance — consider current row a duplicate -> skip\n",
    "                continue\n",
    "\n",
    "        # otherwise, keep this detection\n",
    "        kept_for_group.append(idx)\n",
    "\n",
    "    # extend global kept list\n",
    "    kept_indices.extend(kept_for_group)\n",
    "\n",
    "# create deduplicated DataFrame preserving original relative order of kept rows\n",
    "kept_mask = willow_creek_vehicles.index.isin(kept_indices)\n",
    "willow_creek_vehicles = willow_creek_vehicles.loc[kept_mask].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf25982",
   "metadata": {},
   "source": [
    "Ok, now I feel good about the general confidence level and deduplicating we've applying. There may be more errors to catch, but this way hopefully a single vehicle should be recognized for longer as being in the same place. By vehicle id and class and parking spot, let's capture the earliest time it was seen and last time it was seen. Perhaps let's also capture the lowest confidence and highest confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc7ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make timestamp actual date time object, and turn id into a string\n",
    "willow_creek_vehicles['timestamp_dt'] = pd.to_datetime(willow_creek_vehicles['timestamp'], format='%Y-%m-%d %H-%M-%S')\n",
    "\n",
    "# create concatenated string uniquely identifying vehicles to make my life easier\n",
    "willow_creek_vehicles['id_spot_string'] = willow_creek_vehicles['id'].astype(str) + willow_creek_vehicles['class'].astype(str) + willow_creek_vehicles['parking_spot_id'].astype(str)\n",
    "\n",
    "# output min and max time stamps for each vehicle\n",
    "vehicle_time_boundaries = willow_creek_vehicles.groupby('id_spot_string')['timestamp_dt'].agg(['min', 'max', 'count'])\n",
    "vehicle_confidence_boundaries = willow_creek_vehicles.groupby('id_spot_string')['confidence_numeric'].agg(['min', 'max', 'median'])\n",
    "\n",
    "# merge together\n",
    "unique_vehicles_summary = pd.merge(vehicle_time_boundaries, vehicle_confidence_boundaries, on = 'id_spot_string', suffixes= (\"_time\", \"_conf\"))\n",
    "unique_vehicles_summary = pd.merge(willow_creek_vehicles[['id_spot_string', 'id', 'class', 'parking_spot_id']].drop_duplicates(), unique_vehicles_summary, on = 'id_spot_string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704297d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate length of stay\n",
    "unique_vehicles_summary['length_of_stay_minutes'] = (unique_vehicles_summary['max_time'] - unique_vehicles_summary['min_time']).dt.total_seconds()/60\n",
    "\n",
    "# remove additional entries with overall low confidence\n",
    "unique_vehicles_summary = unique_vehicles_summary[(unique_vehicles_summary['max_conf'] > 0.6) & (unique_vehicles_summary['median'] > 0.5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b97b3f",
   "metadata": {},
   "source": [
    "Additional error resolution is needed, as vehicles may be identified incorrectly multiple times. If one parking spot has multiple vehicles recognized as being present with overlapping time bands, keep only the record with the wider timeband. This should also work by identifying the record with the most counts, but you'd have to identify the time band anyway to know which to remove -- so let's apply this more rigorous approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a09b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nineveh.OConnell\\AppData\\Local\\Temp\\ipykernel_44668\\1145535354.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for spot, group in df.groupby(spot_col, sort=False):\n"
     ]
    }
   ],
   "source": [
    "def keep_widest_nonoverlapping(df, spot_col='parking_spot_id', t0_col='min_time', t1_col='max_time'):\n",
    "\n",
    "    kept_indices = []\n",
    "\n",
    "    # process per spot\n",
    "    for spot, group in df.groupby(spot_col, sort=False):\n",
    "        # sort by duration desc, stable so ties preserve original order\n",
    "        group_sorted = group.sort_values('length_of_stay_minutes', ascending=False, kind='stable')\n",
    "\n",
    "        kept_for_spot = []\n",
    "        kept_intervals = []  # list of (min_time, max_time) for kept intervals\n",
    "\n",
    "        for idx, row in group_sorted.iterrows():\n",
    "            t0 = row[t0_col]\n",
    "            t1 = row[t1_col]\n",
    "            # check overlap with any already-kept interval\n",
    "            # overlap condition: not (t1 <= kept_t0 or t0 >= kept_t1)\n",
    "            overlaps = any((t1 > kt0) and (t0 < kt1) for (kt0, kt1) in kept_intervals)\n",
    "            if not overlaps:\n",
    "                kept_for_spot.append(idx)\n",
    "                kept_intervals.append((t0, t1))\n",
    "\n",
    "        kept_indices.extend(kept_for_spot)\n",
    "\n",
    "    # return filtered dataframe\n",
    "    result = df.loc[kept_indices]\n",
    "    return result\n",
    "\n",
    "# deduplicate nested time spans\n",
    "unique_vehicles_summary_dedup = keep_widest_nonoverlapping(unique_vehicles_summary,\n",
    "                                                         spot_col='parking_spot_id',\n",
    "                                                         t0_col='min_time',\n",
    "                                                         t1_col='max_time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834c231",
   "metadata": {},
   "source": [
    "Ok, great. We end up with a similar number of vehicles to my manual count -- this indicates 14 vehicles (seeing as one is just the truck that was passing by) and I manually counted 15 vehicles over this time period. Vehicles should be unique by id + class, the parking spot identification is tricky and not requisite to deem a vehicle as uniquely identified, though it was useful for deduplication because I specifically looked at nesting time frames (overlapping, non-nested time frames should be permitted). Length of stay should ideally exclude vehicles that were there at the beginning and those that were still there at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f4d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_start_time = unique_vehicles_summary_dedup['min_time'].agg('min')\n",
    "cv_end_time = unique_vehicles_summary_dedup['max_time'].agg('max')\n",
    "\n",
    "# flag as present start of period if so, end of period do the same\n",
    "unique_vehicles_summary_dedup['flag_present_start'] = (unique_vehicles_summary_dedup['min_time'] == cv_start_time)\n",
    "unique_vehicles_summary_dedup['flag_present_end']   = (unique_vehicles_summary_dedup['max_time'] == cv_end_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f9bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique id excepting parking spot id\n",
    "unique_vehicles_summary_dedup['id_string'] = unique_vehicles_summary_dedup['id'].astype(str) + unique_vehicles_summary_dedup['class'].astype(str)\n",
    "\n",
    "# for this operation, drop vehicles that were not in a parking spot\n",
    "parked_cars_only = unique_vehicles_summary_dedup[unique_vehicles_summary_dedup['parking_spot_id'] != '-1']\n",
    "\n",
    "# summarize length of stay by unique car, ignoring spot now\n",
    "parked_cars_only = parked_cars_only.groupby('id_string')[['length_of_stay_minutes', 'flag_present_start', 'flag_present_end']].agg('sum')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94bea7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between  2025-09-30 17:30:26  and  2025-09-30 20:23:29 ,  9  total vehicles were captured at the Willow Creek Trailhead.\n",
      " 4  were already parked when this time period began and  2  were present when this time period ended. \n",
      " We witnessed the beginning and end of the visit to the trailhead for  3  vehicles. The average stay for these vehicles was  43.16111111111112  minutes.\n"
     ]
    }
   ],
   "source": [
    "# count overall unique vehicles in the dataset\n",
    "n_parked_in_period = len(parked_cars_only)\n",
    "# count unique vehicles present at the start\n",
    "n_parked_at_start = sum(parked_cars_only['flag_present_start'] == 1)\n",
    "# count unique vehicles present at the end\n",
    "n_parked_at_end = sum(parked_cars_only['flag_present_end'] == 1)\n",
    "# count unique vehicles for which we witnessed the beginning and end\n",
    "n_whole_stay_witnessed = len(parked_cars_only[(parked_cars_only['flag_present_end'] == 0) & (parked_cars_only['flag_present_start'] == 0)])\n",
    "# average length of stay\n",
    "avg_length_of_stay = parked_cars_only[(parked_cars_only['flag_present_end'] == 0) & (parked_cars_only['flag_present_start'] == 0)]['length_of_stay_minutes'].agg('mean')\n",
    "# print all those things\n",
    "print(\"Between \", cv_start_time, \" and \", cv_end_time, \", \", n_parked_in_period, \" total vehicles were captured at the Willow Creek Trailhead.\\n\", \n",
    "      n_parked_at_start, \" were already parked when this time period began and \", n_parked_at_end, \" were present when this time period ended. \\n \" \\\n",
    "      \"We witnessed the beginning and end of the visit to the trailhead for \",\n",
    "      n_whole_stay_witnessed, \" vehicles. The average stay for these vehicles was \", avg_length_of_stay, \" minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a9862",
   "metadata": {},
   "source": [
    "This looks great! When I run it through with Monday's data pull, I get: \"Between  2025-09-29 10:00:16  and  2025-09-29 14:29:29 ,  15  total vehicles were captured at the Willow Creek Trailhead. 5  were already parked when this time period began and  5  were present when this time period ended. We witnessed the beginning and end of the visit to the trailhead for  6  vehicles. The average stay for these vehicles was  76.325  minutes.\" \n",
    " \n",
    " What does it look like when I run it through with the data pull from Tuesday evening? I can look at it more later... but that's what's in the script right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624e489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Public-Lands-Computer-Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
